q2.1 1. Algorithm            Authors               Complexity         Application 
     Forwards Additive	Lucas-Kanade (1981)	O(n^2*N + n^3)     Any warp
     Forwards Compositional	Shum-Szeliski (2000)	O(n^2*N + n^3)     Any semi-group
     Inverse Additive	Hager-Belhumeur(1998)  O(n*N + n^3)       Simple linear 2D +
     Inverse Compositional  Baker-Matthews (2001)	O(n*N + k*N + k^3) Any group
     2. 算法的目标是有一个模板图像T(x)和一个原始图像I(x)，要求给原始图像做一个wrap变换将像素从T坐标系中中变换到I坐标系中，并求这个变换函数W(x;p)使得经过变换候的图像I(W(x;p))与模板图像T(x)之间的误差平方最小。用数学表达式来描述上边的过程就是：argmin Σ[I(W(x;p)) - T(x)]^2
        相同的图像块在不同的图像中可能发生了一些变化，带wrap变化会使得算法更鲁棒。这里的wrap就可以理解为一个不断迭代，不断优化的一个框图，并且这个框图最终的目标是跟模板图相匹配。
     3. 如果模板中有很多噪声，则应该使用正向算法。如果输入图像中噪声更多，那就采用逆向算法。逆向算法只用计算一次Hessian矩阵，而正向算法需要在每次迭代过程中都计算一遍Hessian矩阵。因此，逆向算法更高效，计算量较小。
        正向法在第二个图像I2处求梯度，而逆向法直接用第一个图像I1处的梯度来代替。
        正向法和逆向法的目标函数也不一样
        正向法: argmin Σ[I(W(w(x;dp);p)) - T(x)]^2
        反向法: argmin Σ[T(W(x;dp)) - I(W(x;p))]^2   
   
q2.2 1. e = I1(x,y) - I2(x+dx, y+dy)
     2. ∂e/∂(dx) = -∂I2/∂(dx) = -(I2(x+dx+1, y+dy) - I(x+dx-1, y+dy)) / 2
        ∂e/∂(dy) = -∂I2/∂(dy) = -(I2(x+dx, y+dy+1) - I(x+dx, y+dy-1)) / 2

q2.3 ∂e/∂(dx) = -∂I2/∂(dx) = -∂I1/∂(dx) = -(I1(x+dx+1, y+dy) - I(x+dx-1, y+dy)) / 2
     ∂e/∂(dy) = -∂I2/∂(dy) = -∂I1/∂(dx) = -(I1(x+dx, y+dy+1) - I(x+dx, y+dy-1)) / 2
   
q2.4 1. 图像金字塔是指对一个图像进行缩放，得到不同分辨率下的图像。以原始图像作为金字塔底层，每往上一层，就对下一层图像进行一定倍率的缩放，就得到了一个金字塔。然后，在计算光流时，先从顶层的图像开始计算，然后把上一层的追踪结果，作为下一层光流的初始值。由于上层图像相对粗糙，所以这个过程也称为由粗至精的光流。
     2. 光流法中使用图像金字塔，可以使得优化过程更容易跳出，由于原始图像像素运动较大导致的优化结果困在极小值的情况。而特征点法金子塔中，金字塔的作用是解决Fast角点，由于远处看着像角点的地方，近处就可能不是角点的尺度问题，给Fast角点增加尺度不变性。

q2.5 并行化分析：
     方法 optical flow single level 平均调用时间/次数: 4.21308/1 毫秒。
     方法 optical flow single level multi-thread 平均调用时间/次数: 5.62147/1 毫秒。

q2.6 1. 优化两个图像块的灰度值之差是在两图灰度值不会变的强前提之下的，如果两张图片中，色彩变化剧烈，那么光流发可能效果就不会那么合理。可以使用图像灰度相对误差来进行光流法，对图像中每个像素值减去均值，得到相对误差来做光流法。
     2. 利用opencv处理所的的结果中，8×8与16×16的图像块并无太大差异。推测可能是由于本题的两张图片中像素变化范围并不大，如果运动范围很大，那么可能调整图像块会有一定影响。
     3. 层数越多，光流法得到的点就越少，并且越往中间聚集，边缘的点就会被忽略掉。
        倍率越小，光流法得到的点就越少，但是倍率的影响要比金字塔的影响更快。

q2实践：See q2_optical_flow

q3.1 1. e = I_ref(π(pi)) - I_cur(π(T_cr * pi))
     2. Ji = ∂e/∂δɛ = - ∂I_cur(π(T_cr * pi))/∂δɛ = -∂I_cur/∂u *  ∂u/∂(T_cr*p) * ∂(T_cr*p)/∂δɛ
        
        ∂I_cur/∂u = [I_cur(u+1,v) - I_cur(u-1,v), I_cur(u,v+1) - T_cur(u,v-1), 0]
        
        设T_cr*p = [X, Y, Z]^T
        ∂u/∂(T_cr*p) = [fx/Z 0    -fx*X/Z^2]
                       [0    fy/Z -fy*Y/Z^2]

        ∂(T_cr*p)/∂δɛ = [I, -(T_cr*p)^]
        
        Ji = - [I_cur(u+1,v)-I_cur(u-1,v), I_cur(u,v+1)-I_cur(u,v-1)] * [fx/Z 0    -fx*X/Z^2] * [I, -(T_cr*p)^]
                       						   [0    fy/Z -fy*Y/Z^2] 
        Ji为1x6的矩阵      						      
     3. 代码中默认的窗口大小为8×8，可以取单点，但是精确度会有所下降。

q3.3 方法 optical flow single level 平均调用时间/次数: 256.725/1 毫秒。
     方法 optical flow single level multi-thread 平均调用时间/次数: 370.966/1 毫秒。
     
q3.4 1. 直接法可以类似光流，提出inverse，compositional，但是没有意义，因为直接法是直接对两个图的光度误差做优化。
     2. 在for循环计算每个点时，可以进行代码并行加速。另外并不是块选择越大越好，选择一个合适的，较小的，效率也会提高。
     3. 灰度值不变，同一个窗口内的深度信息不变。
     4. 因为是直接对光度误差做优化，不需要做特征匹配。
     5. 优点：
	可以省去计算特征点、描述子的时间
	只要求有像素梯度即可，不需要特征点
	可以构建半稠密乃至稠密的地图，是特征点无法做到的
	缺点：
	图像具有非凸性
	单个像素没有区分度
	灰度值不变是很强的假设

q3实践：See direct_method

q4: See optical_disparity

